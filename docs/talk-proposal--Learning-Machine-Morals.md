# Learning Machine Morals

## Abstract

In a world where we interact with machines almost incessantly, the Machine Learning practitioners and Data Scientists that create those machines are treated like magicians, Supermen and Superwomen. With power comes responsibility. That responsibility lies with both the individual and the organizations and communities they are a part of. We will demonstrate some practical Python modules for living up to that responsibility. This discussion is aimed at practitioners of machine learning at all levels. Familiarity with basic statistics and commonly used machine learning Python packages will enable attendees to follow the demonstration and duplicate our results. All attendees will leave the talk with a better understanding of common ethical considerations in machine learning, and useful practical tools for testing findings for indicators of fundamental assumptions, and demonstrating ethical bias in predictions on holdout sets. Recent machine learning technology advances and the availability of large volumes of data make it straight forward to tailor predictions to specific subsets of information content or features. A common ethical issue in ML is the manipulation of rank ordered lists output by predictive models - particularly when weights are assigned according to a personal preference rather than objective criteria alone. Consider the upweighting of university applications for students based on "features" other than pure academic potential, such as the likelihood of a family's ability to make financial contributions to the institution. And consider the implications for everything from the way that search results are displayed when you query Google or Bing - a corollary to the debate about net neutrality - to the way that preferences can be tailored in online dating, organ-donor matching, or hiring. 

## References

[Cowie]: Cowie, Roddy, and Marc Schr√∂der. "Piecing together the emotion jigsaw." Machine Learning for Multimodal Interaction. Springer Berlin Heidelberg, 2005. 305-317.

[Johnson]: Johnson, Jeffrey Alan. "Ethics of data mining and predictive analytics in higher education." Association for Institutional Research Annual Forum, Long Beach, California. 2013.

[Fleischmann]: Fleischmann, Kenneth R., Thomas Clay Templeton, and Jordan Boyd-Graber. "Modeling diverse standpoints in text classification: Learning to be human by modeling human values." Proceedings of the 2011 iConference. ACM, 2011.

[Pasquale]: Pasquale, Frank A. "Internet nondiscrimination principles: commercial ethics for carriers and search engines." Seton Hall Public Law Research Paper1134159 (2008).

## Presenter

[Irene Lang](https://www.linkedin.com/in/irene-lang-ab67a013)

## Contributor

[Hobson Lane](https://www.linkedin.com/in/hobsonlane)