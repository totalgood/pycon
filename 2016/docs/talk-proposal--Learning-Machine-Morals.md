# Learning Machine Morals

## Abstract

In a world where we interact with machines almost incessantly, Data Scientists and Machine Learning experts that create those machines are treated like superheroes. With great power comes great responsibility. That responsibility lies with both the individual and the organizations and communities they are a part of. We will demonstrate some practical, Python modules for living up to that responsibility. The discussion is aimed at practitioners of machine learning at all levels. Familiarity with basic statistics and commonly used machine learning Python packages will enable attendees to follow the demonstration and duplicate our results. Such practitioners will leave the talk with a better understanding of common ethical considerations in machine learning, and useful practical tools for testing findings for indicators of fundamental assumptions, and demonstrating ethical bias in predictions on holdout sets. Machine learning is sufficiently advanced that out of high volumes of noise we can now tailor predictions to very specific subsets of information. A common ethical issue in ML is the manipulation of rank ordered lists output by predictive models - particularly when weights are assigned according to a personal preference rather than objective criteria alone. Consider the upweighting the university applications of students based on "features" other than pure academic potential, such as the likelihood of a family's ability to make financial contributions to the institution. And consider the implications for everything from the way that search results are displayed when you query Google or Bing - a corollary to the debate about net neutrality - to the way that preferences can be tailored in online dating, organ-donor matching, or hiring. 

## References

[Cowie]: Cowie, Roddy, and Marc Schr√∂der. "Piecing together the emotion jigsaw." Machine Learning for Multimodal Interaction. Springer Berlin Heidelberg, 2005. 305-317.

[Johnson]: Johnson, Jeffrey Alan. "Ethics of data mining and predictive analytics in higher education." Association for Institutional Research Annual Forum, Long Beach, California. 2013.

[Fleischmann]: Fleischmann, Kenneth R., Thomas Clay Templeton, and Jordan Boyd-Graber. "Modeling diverse standpoints in text classification: Learning to be human by modeling human values." Proceedings of the 2011 iConference. ACM, 2011.

[Pasquale]: Pasquale, Frank A. "Internet nondiscrimination principles: commercial ethics for carriers and search engines." Seton Hall Public Law Research Paper1134159 (2008).

## Presenter

[Irene Lang](https://www.linkedin.com/in/irene-lang-ab67a013)

## Contributor

[Hobson Lane](https://www.linkedin.com/in/hobsonlane)