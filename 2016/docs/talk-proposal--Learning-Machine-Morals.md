## Title

Learning Machine Morals

## Category

Best Practices

## Duration

30 Minute Slot

## Description 

In a world where we interact with machines almost incessantly, the Machine Learning practitioners and Data Scientists that create those machines are treated like magicians, Supermen and Superwomen. With power comes responsibility. That responsibility lies with both the individual and the organizations and communities they are a part of. We will demonstrate some practical Python modules for living up to that responsibility. 

## Detailed Abstract

In a world where we interact with machines almost incessantly, the Machine Learning practitioners and Data Scientists that create those machines are treated like magicians, Supermen and Superwomen. With power comes responsibility. That responsibility lies with both the individual and the organizations and communities they are a part of. We will demonstrate some practical Python modules for living up to that responsibility. This discussion is aimed at practitioners of machine learning at all levels. Familiarity with basic statistics and commonly used machine learning Python packages will enable attendees to follow the demonstration and duplicate our results. All attendees will leave the talk with a better understanding of common ethical considerations in machine learning, and useful practical tools for testing findings for indicators of fundamental assumptions, and demonstrating ethical bias in predictions on holdout sets. Recent machine learning technology advances and the availability of large volumes of data make it straight forward to tailor predictions to specific subsets of information content or features. A common ethical issue in ML is the manipulation of rank ordered lists output by predictive models - particularly when weights are assigned according to a personal preference rather than objective criteria alone. Consider the unweighting of university applications for students based on “features” other than pure academic potential, such as the likelihood of a family’s ability to make financial contributions to the institution. And consider the implications for everything from the way that search results are displayed when you query Google or Bing - a corollary to the debate about net neutrality - to the way that preferences can be tailored in online dating, organ-donor matching, or hiring. 

## Outline

### Intro (5 min.)

The ethical issues in ML and why you should care about them?

### Lit Review (5 min)

The current consensus in academic literature and popular writing on ethical issues with collaborative search, and predictive analytics?

Practical Example -  (15 min)

	A. Walk through an example with contrived, but realistic data
     that shows the difference in a rank ordered list of college
     applicants when potential financial contribution is weighted
     increasingly heavily.  
  B. Reverse the process: given two rank ordered list of
     preferred candidates, and the set of features used to produce
     the list take a look at the practical code used to determine
     which list was produced using an algorithm biased to prefer
     high financial contributors.  
	C. Conclusion: What are the fundamental questions you have to
     ask in order to implement these ideas in practice, and the
     practical tools used to carry them out? 

Conclusion - Review of critical take aways, next steps, and resources. (5 min)

## Audience

Practitioners with a basic familiarity with machine learning, and commonly used python modules in this space. 

## Objectives 

A. Introduce the basic ethical concepts underlying some applications of machine learning.  

B. Provide the audience with a practical example and python based tools for putting their ethical standards into practice thoughtfully.  

C. Give practitioners a set of resources to continue research and learning on their own.  

## References

[Cowie]: Cowie, Roddy, and Marc Schröder. “Piecing together the emotion jigsaw.” Machine Learning for Multimodal Interaction. Springer Berlin Heidelberg, 2005. 305-317.

[Johnson]: Johnson, Jeffrey Alan. “Ethics of data mining and predictive analytics in higher education.” Association for Institutional Research Annual Forum, Long Beach, California. 2013.

[Fleischmann]: Fleischmann, Kenneth R., Thomas Clay Templeton, and Jordan Boyd-Graber. “Modeling diverse standpoints in text classification: Learning to be human by modeling human values.” Proceedings of the 2011 iConference. ACM, 2011.

[Pasquale]: Pasquale, Frank A. “Internet nondiscrimination principles: commercial ethics for carriers and search engines.” Seton Hall Public Law Research Paper1134159 (2008).


## Presenter


[Irene Lang](https://www.linkedin.com/in/irene-lang-ab67a013)

## Contributor

[Hobson Lane](https://www.linkedin.com/in/hobsonlane)
